{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SJ\\\\Desktop\\\\NLP\\\\Sentiment labeled datasets'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check work directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/SJ/Desktop/NLP/Sentiment labeled datasets/sentiment labelled sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SJ\\\\Desktop\\\\NLP\\\\Sentiment labeled datasets\\\\sentiment labelled sentences'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "imdb_data=pd.read_csv('imdb_labelled.txt',delimiter='\\t',header=None)\n",
    "amazon_data=pd.read_csv('amazon_cells_labelled.txt',delimiter='\\t',header=None)\n",
    "yelp_data=pd.read_csv('yelp_labelled.txt',delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 2)\n",
      "(1000, 2)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Check shapes\n",
    "print(imdb_data.shape)\n",
    "print(amazon_data.shape)\n",
    "print(yelp_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Reviews_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Reviews_class\n",
       "0  A very, very, very slow-moving, aimless movie ...              0\n",
       "1  Not sure who was more lost - the flat characte...              0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine all datasets\n",
    "\n",
    "data=pd.concat([imdb_data,amazon_data,yelp_data])\n",
    "data.columns=['Reviews','Reviews_class']\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey guys  How are you \n",
      "Hey guys  How are you \n"
     ]
    }
   ],
   "source": [
    "#Use case of maketrans() and translate function\n",
    "import string \n",
    "sentence = \"Hey guys !, How are 'you' ?\"\n",
    "no_punc_txt = \"\"\n",
    "for char in sentence:\n",
    "   if char not in string.punctuation:\n",
    "       no_punc_txt = no_punc_txt + char\n",
    "print(no_punc_txt);                 \n",
    "# or:\n",
    "no_punc_txt = sentence.translate(sentence.maketrans('', '', string.punctuation))\n",
    "print(no_punc_txt);                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey guys today im here to explain about Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "sentence=\"Hey guys today i'm here to explain about Natural Language Processing!!!\"\n",
    "no_punc_text=''\n",
    "for char in sentence:\n",
    "    if char not in string.punctuation:\n",
    "        no_punc_text+=char\n",
    "        \n",
    "print(no_punc_text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey guys today im here to explain about Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "# Or another way to do this is\n",
    "table=sentence.maketrans('','',string.punctuation)\n",
    "no_punc_text=sentence.translate(table)\n",
    "print(no_punc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "txt = \"Company\"\n",
    "\n",
    "x = txt.isalpha()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for emoji\n",
    "#https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slowmoving aimless movie distressed drifting young man',\n",
       " 'not sure lost flat characters audience nearly half walked',\n",
       " 'attempting artiness black white clever camera angles movie disappointed became even ridiculous acting poor plot lines almost nonexistent',\n",
       " 'little music anything speak',\n",
       " 'best scene movie gerardo trying find song keeps running head',\n",
       " 'rest movie lacks art charm meaning emptiness works guess empty',\n",
       " 'wasted two hours',\n",
       " 'saw movie today thought good effort good messages kids',\n",
       " 'bit predictable',\n",
       " 'loved casting jimmy buffet science teacher',\n",
       " 'baby owls adorable',\n",
       " 'movie showed lot florida best made look appealing',\n",
       " 'songs best muppets hilarious',\n",
       " 'cool',\n",
       " 'right case movie delivers everything almost right face',\n",
       " 'average acting main person low budget clearly see',\n",
       " 'review long overdue since consider tale two sisters single greatest film ever made',\n",
       " 'put gem movie terms screenplay cinematography acting postproduction editing directing aspect filmmaking',\n",
       " 'practically perfect true masterpiece sea faux masterpieces',\n",
       " 'structure film easily tightly constructed history cinema think film something vitally important occurs every minute words content level film enough easily fill dozen films anyone right mind ask anything movie quite simply highest superlative form cinema imaginable yes film require rather significant amount puzzlesolving pieces fit together create beautiful picture short film certainly pulls punches graphics far best part game number one best th game series deserves strong love insane game massive levels massive unlockable characters massive game waste money game kind money wasted properly actually graphics good time today graphics crap say canada fun game aye game rocks buy play enjoy love pure brilliance flick doomed conception idea lame take minor character mediocre film make complete nonsequel changing tone pgrated family movie nt least bit interested not confirm film would unfunny generic also managed give away entire movie not exaggerating every moment every plot point every joke told trailer not funny even talented carrell not save costars not fare much better people like morgan freeman jonah hill ed helms wasted story predictable lazy real effects work presence animals integration scenes worst obvious bluegreenscreen work ever seen whatever cost much nt translate quality sure film succeeds despite perhaps obviously meagre budget glad film nt go obvious choice lesser film certainly would addition one lovely songs ever written french cancan also boasts one cutest leading ladies ever grace screen hard not fall headoverheels love girl negative insipid enough cause regret another hours life wasted front screen long whiny pointless recommend waiting future efforts let one go excellent cast story line performances totally believable anne heche utterly convincing sam shepard portrayal gung ho marine sobering sat riveted tv screen give one resounding think tom hanks good actor enjoyed reading book children little disappointed movie one character totally annoying voice gives feeling fingernails chalkboard totally unnecessary trainroller coaster scene absolutely warmth charm scenes characters movie totally grates nerves performances not improved improvisation actors twice much worry not whether delivering line well whether line good quite honestly often not good often dialogue nt really follow one line another fit surroundings crackles unpredictable youthful energy honestly found hard follow concentrate meanders badly generally great things would nt say worth hours time though suspense builders good cross line g pg especially liked noncliche choices parents movies could predict dialog verbatim writing movie made better selections want movie not gross gives chills great choice alexander nevsky great film amazing film artist one important whoever lived glad pretentious piece nt planned dodge stratus big shots gon na help movie makers nt restrained movie business qu√©bec']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    all_reviews=[]\n",
    "    lines=df['Reviews'].values.tolist()\n",
    "    for text in lines:\n",
    "        text=text.lower()\n",
    "        pattern=re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text=pattern.sub('',text)\n",
    "        emoji = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001FFFF\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        text=emoji.sub('',text)\n",
    "        text=re.sub(r\"i'm\", \"i am\",text)\n",
    "        text=re.sub(r\"he's\", \"he is\",text)\n",
    "        text=re.sub(r\"she's\",\"she is\",text)\n",
    "        text=re.sub(r\"that's\", \"that is\",text)\n",
    "        text=re.sub(r\"what's\",\"what is\",text)\n",
    "        text = re.sub(r\"where's\", \"where is\", text) \n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)  \n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)  \n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"don't\", \"do not\", text)\n",
    "        text = re.sub(r\"did't\", \"did not\", text)\n",
    "        text = re.sub(r\"can't\", \"can not\", text)\n",
    "        text = re.sub(r\"it's\", \"it is\", text)\n",
    "        text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "        text = re.sub(r\"have't\", \"have not\", text)\n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        tokens = word_tokenize(text)\n",
    "        #USE str.maketrans() and str.translate() to remove punctuation from a string\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        words = ' '.join(words)\n",
    "        all_reviews.append(words)\n",
    "    return all_reviews\n",
    "\n",
    "all_reviews = clean_text(data)\n",
    "all_reviews[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would good looking wealthy man move country become veterinarian marry country hick']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the performance with any text \n",
    "df=pd.DataFrame(['https://Why would a good looking wealthy man move to the country, become a veterinarian and marry a country hick?'])\n",
    "\n",
    "df.columns=['Reviews']\n",
    "\n",
    "clean_text(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
